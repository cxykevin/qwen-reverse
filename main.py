# pip install requests flask flask-cors

import requests
import uuid
import time
import json
import os
import warnings
import sqlite3
import re
import html
from flask import Flask, request, jsonify, Response, stream_with_context
from flask_cors import CORS

# ==================== é…ç½®åŒºåŸŸ ====================
# è¯·å°†æ‚¨çš„æœ‰æ•ˆ token æ”¾åœ¨è¿™é‡Œï¼Œæˆ–é€šè¿‡ç¯å¢ƒå˜é‡ QWEN_AUTH_TOKEN è®¾ç½®
QWEN_AUTH_TOKEN = os.environ.get("QWEN_AUTH_TOKEN")
if not QWEN_AUTH_TOKEN:
    # å¦‚æœç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·åœ¨æ­¤å¤„ç›´æ¥å¡«å†™ä½ çš„ token
    QWEN_AUTH_TOKEN = ""
IS_DELETE = 0  # æ˜¯å¦åœ¨ä¼šè¯ç»“æŸåè‡ªåŠ¨åˆ é™¤ä¼šè¯
PORT = 5000  # æœåŠ¡ç«¯ç»‘å®šçš„ç«¯å£
DEBUG_STATUS = False  # æ˜¯å¦è¾“å‡ºdebugä¿¡æ¯
DATABASE_PATH = "chat_history.db"  # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
# æ¨¡å‹æ˜ å°„ï¼ŒåŸºäºå®é™…è¿”å›çš„æ¨¡å‹åˆ—è¡¨
MODEL_MAP = {
    "qwen": "qwen3-235b-a22b", # é»˜è®¤æ——èˆ°æ¨¡å‹
    "qwen3": "qwen3-235b-a22b",
    "qwen3-coder": "qwen3-coder-plus",
    "qwen3-moe": "qwen3-235b-a22b",
    "qwen3-dense": "qwen3-32b",
    "qwen-max": "qwen-max-latest",
    "qwen-plus": "qwen-plus-2025-01-25",
    "qwen-turbo": "qwen-turbo-2025-02-11",
    "qwq": "qwq-32b",
    # OpenAI å¸¸è§æ¨¡å‹æ˜ å°„åˆ° Qwen å¯¹åº”èƒ½åŠ›æ¨¡å‹
    "gpt-3.5-turbo": "qwen-turbo-2025-02-11", # å¿«é€Ÿé«˜æ•ˆ
    "gpt-4": "qwen-plus-2025-01-25",         # å¤æ‚ä»»åŠ¡
    "gpt-4-turbo": "qwen3-235b-a22b",       # æœ€å¼ºå¤§
}
# =================================================

os.environ['FLASK_ENV'] = 'production'  # æˆ– production
os.environ['FLASK_DEBUG'] = '0'
warnings.filterwarnings("ignore", message=".*development server.*")

def debug_print(message):
    """æ ¹æ®DEBUG_STATUSå†³å®šæ˜¯å¦è¾“å‡ºdebugä¿¡æ¯"""
    if DEBUG_STATUS:
        print(f"[DEBUG] {message}")

def remove_tool(text):
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… <tool_use>...</tool_use>ï¼ŒåŒ…æ‹¬è·¨è¡Œå†…å®¹
    pattern = r'<tool_use>.*?</tool_use>'
    # flags=re.DOTALL ä½¿å¾— . å¯ä»¥åŒ¹é…æ¢è¡Œç¬¦
    cleaned_text = re.sub(pattern, '', text, flags=re.DOTALL)
    return cleaned_text

class ChatHistoryManager:
    """ç®¡ç†èŠå¤©å†å²è®°å½•çš„æœ¬åœ°å­˜å‚¨"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        conn = sqlite3.connect(self.db_path)
        try:
            cursor = conn.cursor()
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS chat_sessions (
                    chat_id TEXT PRIMARY KEY,
                    title TEXT,
                    created_at INTEGER,
                    updated_at INTEGER,
                    chat_type TEXT,
                    current_response_id TEXT,
                    last_assistant_content TEXT
                )
            ''')
            conn.commit()
            debug_print("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        finally:
            conn.close()
    
    def update_session(self, chat_id: str, title: str, created_at: int, updated_at: int, 
                      chat_type: str, current_response_id: str, last_assistant_content: str):
        """æ›´æ–°æˆ–æ’å…¥ä¼šè¯è®°å½•"""
        conn = sqlite3.connect(self.db_path)
        try:
            cursor = conn.cursor()
            cursor.execute('''
                INSERT OR REPLACE INTO chat_sessions 
                (chat_id, title, created_at, updated_at, chat_type, current_response_id, 
                 last_assistant_content)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (chat_id, title, created_at, updated_at, chat_type, current_response_id,
                  remove_tool(last_assistant_content)))
            conn.commit()
            debug_print(f"æ›´æ–°ä¼šè¯è®°å½•: {chat_id}")
        finally:
            conn.close()
    
    def get_session_by_last_content(self, content: str):
        """æ ¹æ®æœ€æ–°AIå›å¤å†…å®¹æŸ¥æ‰¾ä¼šè¯"""
        normalized_content = self.normalize_text(content)
        debug_print(f"æŸ¥æ‰¾ä¼šè¯ï¼Œæ ‡å‡†åŒ–å†…å®¹: {normalized_content[:100]}...")
        
        conn = sqlite3.connect(self.db_path)
        try:
            cursor = conn.cursor()
            cursor.execute('''
                SELECT chat_id, current_response_id, last_assistant_content
                FROM chat_sessions 
                WHERE last_assistant_content IS NOT NULL
            ''')
            results = cursor.fetchall()
            
            debug_print(f"æ•°æ®åº“ä¸­å…±æœ‰ {len(results)} æ¡ä¼šè¯è®°å½•")
            
            for row in results:
                chat_id, current_response_id, stored_content = row
                normalized_stored = self.normalize_text(stored_content)
                debug_print(f"æ¯”è¾ƒä¼šè¯ {chat_id}...")
                
                if normalized_content == normalized_stored:
                    debug_print(f"åŒ¹é…æˆåŠŸï¼ä¼šè¯ID: {chat_id}")
                    return {
                        'chat_id': chat_id,
                        'current_response_id': current_response_id
                    }
            
            debug_print("æœªæ‰¾åˆ°åŒ¹é…çš„ä¼šè¯")
            return None
        finally:
            conn.close()
    
    def delete_session(self, chat_id: str):
        """åˆ é™¤ä¼šè¯è®°å½•"""
        conn = sqlite3.connect(self.db_path)
        try:
            cursor = conn.cursor()
            cursor.execute('DELETE FROM chat_sessions WHERE chat_id = ?', (chat_id,))
            conn.commit()
            debug_print(f"åˆ é™¤ä¼šè¯è®°å½•: {chat_id}")
        finally:
            conn.close()
    
    def clear_all_sessions(self):
        """æ¸…ç©ºæ‰€æœ‰ä¼šè¯è®°å½•"""
        conn = sqlite3.connect(self.db_path)
        try:
            cursor = conn.cursor()
            cursor.execute('DELETE FROM chat_sessions')
            conn.commit()
            debug_print("æ¸…ç©ºæ‰€æœ‰ä¼šè¯è®°å½•")
        finally:
            conn.close()
    
    def normalize_text(self, text: str) -> str:
        """æ ‡å‡†åŒ–æ–‡æœ¬ï¼Œå¤„ç†è½¬ä¹‰å­—ç¬¦ã€ç©ºç™½ç¬¦ç­‰"""
        if not text:
            return ""
        
        # HTMLè§£ç 
        text = html.unescape(text)
        # å»é™¤å¤šä½™ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text.strip())
        # å»é™¤å¸¸è§çš„markdownç¬¦å·
        text = re.sub(r'[*_`~]', '', text)
        # å»é™¤emojiï¼ˆç®€å•å¤„ç†ï¼‰
        text = re.sub(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FFâœ¨ğŸŒŸ]', '', text)
        
        return text

class QwenClient:
    """
    ç”¨äºä¸ chat.qwen.ai API äº¤äº’çš„å®¢æˆ·ç«¯ã€‚
    å°è£…äº†åˆ›å»ºå¯¹è¯ã€å‘é€æ¶ˆæ¯ã€æ¥æ”¶æµå¼å“åº”åŠåˆ é™¤å¯¹è¯çš„é€»è¾‘ã€‚
    """
    def __init__(self, auth_token: str, base_url: str = "https://chat.qwen.ai"):
        self.auth_token = auth_token
        self.base_url = base_url
        self.session = requests.Session()
        self.history_manager = ChatHistoryManager(DATABASE_PATH)
        # åˆå§‹åŒ–æ—¶è®¾ç½®åŸºæœ¬è¯·æ±‚å¤´
        self.session.headers.update({
            "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
            "content-type": "application/json",
            "source": "web",
        })
        self.user_info = None
        self.models_info = None
        self.user_settings = None
        self._initialize()
        # å¯åŠ¨æ—¶åŒæ­¥å†å²è®°å½•
        self.sync_history_from_cloud()

    def _initialize(self):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼Œè·å–ç”¨æˆ·ä¿¡æ¯ã€æ¨¡å‹åˆ—è¡¨å’Œç”¨æˆ·è®¾ç½®"""
        self._update_auth_header()
        try:
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info_res = self.session.get(f"{self.base_url}/api/v1/auths/")
            user_info_res.raise_for_status()
            self.user_info = user_info_res.json()

            # è·å–æ¨¡å‹åˆ—è¡¨
            models_res = self.session.get(f"{self.base_url}/api/models")
            models_res.raise_for_status()
            self.models_info = {model['id']: model for model in models_res.json()['data']}

            # è·å–ç”¨æˆ·è®¾ç½®
            settings_res = self.session.get(f"{self.base_url}/api/v2/users/user/settings")
            settings_res.raise_for_status()
            self.user_settings = settings_res.json()['data']

        except requests.exceptions.RequestException as e:
            print(f"å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _update_auth_header(self):
        """æ›´æ–°ä¼šè¯ä¸­çš„è®¤è¯å¤´"""
        self.session.headers.update({"authorization": f"Bearer {self.auth_token}"})

    def sync_history_from_cloud(self):
        """ä»äº‘ç«¯åŒæ­¥å†å²è®°å½•åˆ°æœ¬åœ°æ•°æ®åº“"""
        debug_print("å¼€å§‹ä»äº‘ç«¯åŒæ­¥å†å²è®°å½•")
        self._update_auth_header()
        
        try:
            # æ¸…ç©ºæœ¬åœ°è®°å½•
            self.history_manager.clear_all_sessions()
            
            page = 1
            while True:
                # è·å–å†å²ä¼šè¯åˆ—è¡¨
                list_url = f"{self.base_url}/api/v2/chats/?page={page}"
                response = self.session.get(list_url)
                response.raise_for_status()
                data = response.json()
                
                if not data.get('success') or not data.get('data'):
                    break
                
                sessions = data['data']
                debug_print(f"ç¬¬ {page} é¡µè·å–åˆ° {len(sessions)} ä¸ªä¼šè¯")
                
                if not sessions:
                    break
                
                # è·å–æ¯ä¸ªä¼šè¯çš„è¯¦ç»†ä¿¡æ¯
                for session in sessions:
                    chat_id = session['id']
                    try:
                        detail_url = f"{self.base_url}/api/v2/chats/{chat_id}"
                        detail_response = self.session.get(detail_url)
                        detail_response.raise_for_status()
                        detail_data = detail_response.json()
                        
                        if not detail_data.get('success'):
                            continue
                        
                        chat_detail = detail_data['data']
                        messages = chat_detail.get('chat', {}).get('messages', [])
                        
                        # æå–æœ€æ–°çš„AIå›å¤å†…å®¹
                        last_assistant_content = ""
                        for msg in reversed(messages):
                            if msg.get('role') == 'assistant':
                                # ä»content_listä¸­æå–å†…å®¹
                                content_list = msg.get('content_list', [])
                                if content_list:
                                    last_assistant_content = content_list[-1].get('content', '')
                                else:
                                    last_assistant_content = msg.get('content', '')
                                break
                        
                        # ä¿å­˜åˆ°æœ¬åœ°æ•°æ®åº“
                        current_response_id = chat_detail.get('currentId', '')
                        
                        self.history_manager.update_session(
                            chat_id=chat_id,
                            title=session.get('title', ''),
                            created_at=session.get('created_at', 0),
                            updated_at=session.get('updated_at', 0),
                            chat_type=session.get('chat_type', ''),
                            current_response_id=current_response_id,
                            last_assistant_content=last_assistant_content
                        )
                        
                    except Exception as e:
                        debug_print(f"è·å–ä¼šè¯ {chat_id} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}")
                        continue
                
                page += 1
                
            debug_print("å†å²è®°å½•åŒæ­¥å®Œæˆ")
            
        except Exception as e:
            debug_print(f"åŒæ­¥å†å²è®°å½•å¤±è´¥: {e}")

    def _get_qwen_model_id(self, openai_model: str) -> str:
        """å°† OpenAI æ¨¡å‹åç§°æ˜ å°„åˆ° Qwen æ¨¡å‹ ID"""
        # å¦‚æœç›´æ¥åŒ¹é…åˆ° keyï¼Œåˆ™ä½¿ç”¨æ˜ å°„å€¼ï¼›å¦åˆ™å°è¯•çœ‹æ¨¡å‹ ID æ˜¯å¦ç›´æ¥å­˜åœ¨äº Qwen æ¨¡å‹åˆ—è¡¨ä¸­ï¼›æœ€åå›é€€åˆ°é»˜è®¤æ¨¡å‹
        mapped_id = MODEL_MAP.get(openai_model)
        if mapped_id and mapped_id in self.models_info:
            return mapped_id
        elif openai_model in self.models_info:
            return openai_model # OpenAI æ¨¡å‹åæ°å¥½ä¸ Qwen ID ç›¸åŒ
        else:
            print(f"æ¨¡å‹ '{openai_model}' æœªæ‰¾åˆ°æˆ–æœªæ˜ å°„ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹ 'qwen3-235b-a22b'")
            return "qwen3-235b-a22b" # æœ€å¯é çš„å›é€€é€‰é¡¹

    def create_chat(self, model_id: str, title: str = "æ–°å¯¹è¯") -> str:
        """åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è¯"""
        self._update_auth_header() # ç¡®ä¿ token æ˜¯æœ€æ–°çš„
        url = f"{self.base_url}/api/v2/chats/new"
        payload = {
            "title": title,
            "models": [model_id],
            "chat_mode": "normal",
            "chat_type": "t2t", # Text to Text
            "timestamp": int(time.time() * 1000)
        }
        try:
            response = self.session.post(url, json=payload)
            response.raise_for_status()
            chat_id = response.json()['data']['id']
            debug_print(f"æˆåŠŸåˆ›å»ºå¯¹è¯: {chat_id}")
            return chat_id
        except requests.exceptions.RequestException as e:
            debug_print(f"åˆ›å»ºå¯¹è¯å¤±è´¥: {e}")
            raise

    def delete_chat(self, chat_id: str):
        """åˆ é™¤ä¸€ä¸ªå¯¹è¯"""
        self._update_auth_header() # ç¡®ä¿ token æ˜¯æœ€æ–°çš„
        url = f"{self.base_url}/api/v2/chats/{chat_id}"
        
        try:
            response = self.session.delete(url)
            response.raise_for_status()
            res_data = response.json()
            if res_data.get('success', False):
                debug_print(f"æˆåŠŸåˆ é™¤å¯¹è¯: {chat_id}")
                # åŒæ—¶åˆ é™¤æœ¬åœ°è®°å½•
                self.history_manager.delete_session(chat_id)
                return True
            else:
                debug_print(f"åˆ é™¤å¯¹è¯ {chat_id} è¿”å› success=False: {res_data}")
                return False
        except requests.exceptions.RequestException as e:
            debug_print(f"åˆ é™¤å¯¹è¯å¤±è´¥ {chat_id}: {e}")
            return False
        except json.JSONDecodeError:
            debug_print(f"åˆ é™¤å¯¹è¯æ—¶æ— æ³•è§£æ JSON å“åº” {chat_id}")
            return False

    def find_matching_session(self, messages: list):
        """æ ¹æ®æ¶ˆæ¯å†å²æŸ¥æ‰¾åŒ¹é…çš„ä¼šè¯"""
        debug_print("å¼€å§‹æŸ¥æ‰¾åŒ¹é…çš„ä¼šè¯")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰AIå›å¤å†å²
        last_assistant_message = None
        for msg in reversed(messages):
            if msg.get('role') == 'assistant':
                last_assistant_message = msg
                break
        
        if not last_assistant_message:
            debug_print("è¯·æ±‚ä¸­æ²¡æœ‰AIå›å¤å†å²ï¼Œå°†åˆ›å»ºæ–°ä¼šè¯")
            return None
        
        last_content = last_assistant_message.get('content', '')
        if not last_content:
            debug_print("æœ€æ–°AIå›å¤å†…å®¹ä¸ºç©ºï¼Œå°†åˆ›å»ºæ–°ä¼šè¯")
            return None
        
        debug_print("æŸ¥æ‰¾åŒ¹é…...")
        
        # æŸ¥æ‰¾åŒ¹é…çš„ä¼šè¯
        matched_session = self.history_manager.get_session_by_last_content(last_content)
        
        if matched_session:
            debug_print(f"æ‰¾åˆ°åŒ¹é…çš„ä¼šè¯: {matched_session['chat_id']}")
            return matched_session
        else:
            debug_print("æœªæ‰¾åˆ°åŒ¹é…çš„ä¼šè¯ï¼Œå°†åˆ›å»ºæ–°ä¼šè¯")
            return None

    def update_session_after_chat(self, chat_id: str, title: str, messages: list, 
                                  current_response_id: str, assistant_content: str):
        """èŠå¤©ç»“æŸåæ›´æ–°ä¼šè¯è®°å½•"""
        debug_print(f"æ›´æ–°ä¼šè¯è®°å½•: {chat_id}")
        
        current_time = int(time.time())
        
        self.history_manager.update_session(
            chat_id=chat_id,
            title=title,
            created_at=current_time,
            updated_at=current_time,
            chat_type="t2t",
            current_response_id=current_response_id,
            last_assistant_content=assistant_content
        )

    def chat_completions(self, openai_request: dict):
        """
        æ‰§è¡ŒèŠå¤©è¡¥å…¨ï¼Œæ¨¡æ‹Ÿ OpenAI APIã€‚
        è¿”å›æµå¼ç”Ÿæˆå™¨æˆ–éæµå¼ JSON å“åº”ã€‚
        """
        self._update_auth_header() # ç¡®ä¿ token æ˜¯æœ€æ–°çš„
        
        # è§£æ OpenAI è¯·æ±‚
        model = openai_request.get("model", "qwen3")
        messages = openai_request.get("messages", [])
        stream = openai_request.get("stream", False)
        # è§£ææ–°å¢å‚æ•°
        enable_thinking = openai_request.get("enable_thinking", True) # é»˜è®¤å¯ç”¨æ€è€ƒ
        thinking_budget = openai_request.get("thinking_budget", None) # é»˜è®¤ä¸æŒ‡å®š

        # æ˜ å°„æ¨¡å‹
        qwen_model_id = self._get_qwen_model_id(model)

        debug_print(f"æ”¶åˆ°èŠå¤©è¯·æ±‚ï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)}, æ¨¡å‹: {qwen_model_id}")
        # debug_print(f"æ”¶åˆ°çš„å®Œæ•´è¯·æ±‚: \n{openai_request}\n")

        # æŸ¥æ‰¾åŒ¹é…çš„ç°æœ‰ä¼šè¯
        matched_session = self.find_matching_session(messages)
        
        chat_id = None
        parent_id = None
        user_input = ""
        
        if matched_session:
            # ä½¿ç”¨ç°æœ‰ä¼šè¯è¿›è¡Œå¢é‡èŠå¤©
            chat_id = matched_session['chat_id']
            parent_id = matched_session['current_response_id']
            
            # åªå–æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯
            for msg in reversed(messages):
                if msg.get('role') == 'user':
                    user_input = msg.get('content', '')
                    break
            
            debug_print(f"ä½¿ç”¨ç°æœ‰ä¼šè¯ {chat_id}ï¼Œparent_id: {parent_id}")
            # debug_print(f"ç”¨æˆ·è¾“å…¥: {user_input[:100]}...")
            
        else:
            # åˆ›å»ºæ–°ä¼šè¯ï¼Œæ‹¼æ¥æ‰€æœ‰æ¶ˆæ¯
            formatted_history = "\n\n".join([f"{msg['role']}: {msg['content']}" for msg in messages])
            if messages and messages[0]['role'] != "system":
                formatted_history = "system:\n\n" + formatted_history
            user_input = formatted_history
            
            chat_id = self.create_chat(qwen_model_id, title=f"OpenAI_API_å¯¹è¯_{int(time.time())}")
            parent_id = None
            
            debug_print(f"åˆ›å»ºæ–°ä¼šè¯ {chat_id}")

        try:
            # å‡†å¤‡è¯·æ±‚è´Ÿè½½
            timestamp_ms = int(time.time() * 1000)
            
            # æ„å»º feature_config
            feature_config = {
                "output_schema": "phase"
            }
            if enable_thinking:
                feature_config["thinking_enabled"] = True
                # å¦‚æœæä¾›äº† thinking_budget åˆ™ä½¿ç”¨ï¼Œå¦åˆ™å°è¯•ä»ç”¨æˆ·è®¾ç½®è·å–
                if thinking_budget is not None:
                    feature_config["thinking_budget"] = thinking_budget
                else:
                    # å°è¯•ä»ç”¨æˆ·è®¾ç½®ä¸­è·å–é»˜è®¤çš„ thinking_budget
                    default_budget = self.user_settings.get('model_config', {}).get(qwen_model_id, {}).get('thinking_budget')
                    if default_budget:
                        feature_config["thinking_budget"] = default_budget
            else:
                feature_config["thinking_enabled"] = False

            payload = {
                "stream": True, # å§‹ç»ˆä½¿ç”¨æµå¼ä»¥è·å–å®æ—¶æ•°æ®
                "incremental_output": True,
                "chat_id": chat_id,
                "chat_mode": "normal",
                "model": qwen_model_id,
                "parent_id": parent_id,
                "messages": [{
                    "fid": str(uuid.uuid4()),
                    "parentId": parent_id,
                    "childrenIds": [str(uuid.uuid4())],
                    "role": "user",
                    "content": user_input,
                    "user_action": "chat",
                    "files": [],
                    "timestamp": timestamp_ms,
                    "models": [qwen_model_id],
                    "chat_type": "t2t",
                    "feature_config": feature_config,
                    "extra": {"meta": {"subChatType": "t2t"}},
                    "sub_chat_type": "t2t",
                    "parent_id": parent_id
                }],
                "timestamp": timestamp_ms
            }

            # æ·»åŠ å¿…è¦çš„å¤´
            headers = {
                "x-accel-buffering": "no" # å¯¹äºæµå¼å“åº”å¾ˆé‡è¦
            }

            url = f"{self.base_url}/api/v2/chat/completions?chat_id={chat_id}"
            
            if stream:
                # æµå¼è¯·æ±‚
                def generate():
                    try:
                        # ä½¿ç”¨æµå¼è¯·æ±‚ï¼Œå¹¶ç¡®ä¿ä¼šè¯èƒ½æ­£ç¡®å¤„ç†è¿æ¥
                        with self.session.post(url, json=payload, headers=headers, stream=True) as r:
                            r.raise_for_status()
                            finish_reason = "stop"
                            reasoning_text = ""  # ç”¨äºç´¯ç§¯ thinking é˜¶æ®µçš„å†…å®¹
                            assistant_content = ""  # ç”¨äºç´¯ç§¯assistantå›å¤å†…å®¹
                            has_sent_content = False # æ ‡è®°æ˜¯å¦å·²ç»å¼€å§‹å‘é€ answer å†…å®¹
                            current_response_id = None  # å½“å‰å›å¤ID

                            for line in r.iter_lines(decode_unicode=True):
                                # æ£€æŸ¥æ ‡å‡†çš„ SSE å‰ç¼€
                                if line.startswith("data: "):
                                    data_str = line[6:]  # ç§»é™¤ 'data: '
                                    if data_str.strip() == "[DONE]":
                                        # å‘é€æœ€ç»ˆçš„ done æ¶ˆæ¯å—ï¼ŒåŒ…å« finish_reason
                                        final_chunk = {
                                            "id": f"chatcmpl-{chat_id[:10]}",
                                            "object": "chat.completion.chunk",
                                            "created": int(time.time()),
                                            "model": model,
                                            "choices": [{
                                                "index": 0,
                                                "delta": {}, 
                                                "finish_reason": finish_reason
                                            }]
                                        }
                                        yield f"data: {json.dumps(final_chunk)}\n\n"
                                        yield "data: [DONE]\n\n"
                                        break
                                    try:
                                        data = json.loads(data_str)
                                        
                                        # æå–response_id
                                        if "response.created" in data:
                                            current_response_id = data["response.created"].get("response_id")
                                            debug_print(f"è·å–åˆ°response_id: {current_response_id}")
                                        
                                        # å¤„ç† choices æ•°æ®
                                        if "choices" in data and len(data["choices"]) > 0:
                                            choice = data["choices"][0]
                                            delta = choice.get("delta", {})
                                            
                                            # --- é‡æ„é€»è¾‘ï¼šæ¸…æ™°åŒºåˆ† think å’Œ answer é˜¶æ®µ ---
                                            phase = delta.get("phase")
                                            status = delta.get("status")
                                            content = delta.get("content", "")

                                            # 1. å¤„ç† "think" é˜¶æ®µ
                                            if phase == "think":
                                                if status != "finished":
                                                    reasoning_text += content
                                                # æ³¨æ„ï¼šthink é˜¶æ®µçš„å†…å®¹ä¸ç›´æ¥å‘é€ï¼Œåªç´¯ç§¯

                                            # 2. å¤„ç† "answer" é˜¶æ®µ æˆ– æ— æ˜ç¡® phase çš„å†…å®¹ (å…¼å®¹æ€§)
                                            elif phase == "answer" or (phase is None and content):
                                                # ä¸€æ—¦è¿›å…¥ answer é˜¶æ®µæˆ–æœ‰å†…å®¹ï¼Œæ ‡è®°ä¸ºå·²å¼€å§‹
                                                has_sent_content = True 
                                                assistant_content += content  # ç´¯ç§¯assistantå›å¤
                                                
                                                # æ„é€ åŒ…å« content çš„æµå¼å—
                                                openai_chunk = {
                                                    "id": f"chatcmpl-{chat_id[:10]}",
                                                    "object": "chat.completion.chunk",
                                                    "created": int(time.time()),
                                                    "model": model,
                                                    "choices": [{
                                                        "index": 0,
                                                        "delta": {"content": content},
                                                        "finish_reason": None # answer é˜¶æ®µè¿›è¡Œä¸­ä¸è®¾ finish_reason
                                                    }]
                                                }
                                                # å¦‚æœç´¯ç§¯äº† reasoning_textï¼Œåˆ™åœ¨ç¬¬ä¸€ä¸ª answer å—ä¸­é™„å¸¦
                                                if reasoning_text:
                                                     openai_chunk["choices"][0]["delta"]["reasoning_content"] = reasoning_text
                                                     reasoning_text = "" # å‘é€åæ¸…ç©º

                                                yield f"data: {json.dumps(openai_chunk)}\n\n"

                                            # 3. å¤„ç†ç»“æŸä¿¡å· (é€šå¸¸åœ¨ answer é˜¶æ®µçš„æœ€åä¸€ä¸ªå—)
                                            if status == "finished":
                                                finish_reason = delta.get("finish_reason", "stop")

                                    except json.JSONDecodeError:
                                        continue
                    except requests.exceptions.RequestException as e:
                        debug_print(f"æµå¼è¯·æ±‚å¤±è´¥: {e}")
                        # å‘é€ä¸€ä¸ªé”™è¯¯å—
                        error_chunk = {
                            "id": f"chatcmpl-error",
                            "object": "chat.completion.chunk",
                            "created": int(time.time()),
                            "model": model,
                            "choices": [{
                                "index": 0,
                                "delta": {"content": f"Error during streaming: {str(e)}"},
                                "finish_reason": "error"
                            }]
                        }
                        yield f"data: {json.dumps(error_chunk)}\n\n"
                    finally:
                        # èŠå¤©ç»“æŸåæ›´æ–°ä¼šè¯è®°å½•
                        if assistant_content and current_response_id:
                            # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯å†å²
                            updated_messages = messages.copy()
                            updated_messages.append({
                                "role": "assistant",
                                "content": assistant_content
                            })
                            
                            self.update_session_after_chat(
                                chat_id=chat_id,
                                title=f"OpenAI_API_å¯¹è¯_{int(time.time())}",
                                messages=updated_messages,
                                current_response_id=current_response_id,
                                assistant_content=assistant_content
                            )

                return generate()

            else:
                # éæµå¼è¯·æ±‚: èšåˆæµå¼å“åº”
                response_text = ""  # ç”¨äºèšåˆæœ€ç»ˆå›å¤
                reasoning_text = "" # ç”¨äºèšåˆ thinking é˜¶æ®µçš„å†…å®¹
                finish_reason = "stop"
                usage_data = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}
                current_response_id = None
                
                try:
                    with self.session.post(url, json=payload, headers=headers, stream=True) as r:
                        r.raise_for_status()
                        for line in r.iter_lines(decode_unicode=True):
                            # æ£€æŸ¥å®Œæ•´çš„ SSE å‰ç¼€
                            if line.startswith("data: "): 
                                data_str = line[6:] # ç§»é™¤ 'data: '
                                if data_str.strip() == "[DONE]":
                                    break
                                try:
                                    data = json.loads(data_str)
                                    
                                    # æå–response_id
                                    if "response.created" in data:
                                        current_response_id = data["response.created"].get("response_id")
                                    
                                    # å¤„ç† choices æ•°æ®æ¥æ„å»ºæœ€ç»ˆå›å¤
                                    if "choices" in data and len(data["choices"]) > 0:
                                        delta = data["choices"][0].get("delta", {})
                                        
                                        # ç´¯ç§¯ "think" é˜¶æ®µçš„å†…å®¹
                                        if delta.get("phase") == "think":
                                            if delta.get("status") != "finished":
                                                reasoning_text += delta.get("content", "")
                                        
                                        # åªèšåˆ "answer" é˜¶æ®µçš„å†…å®¹
                                        if delta.get("phase") == "answer":
                                            if delta.get("status") != "finished":
                                                response_text += delta.get("content", "")
                                        
                                        # æ”¶é›†æœ€åä¸€æ¬¡çš„ usage ä¿¡æ¯
                                        if "usage" in data:
                                            qwen_usage = data["usage"]
                                            usage_data = {
                                                "prompt_tokens": qwen_usage.get("input_tokens", 0),
                                                "completion_tokens": qwen_usage.get("output_tokens", 0),
                                                "total_tokens": qwen_usage.get("total_tokens", 0),
                                            }
                                    
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æŸä¿¡å·
                                    if "choices" in data and len(data["choices"]) > 0:
                                        delta = data["choices"][0].get("delta", {})
                                        if delta.get("status") == "finished":
                                            finish_reason = delta.get("finish_reason", "stop")
                                        
                                except json.JSONDecodeError:
                                    # å¿½ç•¥æ— æ³•è§£æçš„è¡Œ
                                    continue
                    
                    # èŠå¤©ç»“æŸåæ›´æ–°ä¼šè¯è®°å½•
                    if response_text and current_response_id:
                        # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯å†å²
                        updated_messages = messages.copy()
                        updated_messages.append({
                            "role": "assistant",
                            "content": response_text
                        })
                        
                        self.update_session_after_chat(
                            chat_id=chat_id,
                            title=f"OpenAI_API_å¯¹è¯_{int(time.time())}",
                            messages=updated_messages,
                            current_response_id=current_response_id,
                            assistant_content=response_text
                        )
                    
                    # æ„é€ éæµå¼çš„ OpenAI å“åº”
                    openai_response = {
                        "id": f"chatcmpl-{chat_id[:10]}",
                        "object": "chat.completion",
                        "created": int(time.time()),
                        "model": model,
                        "choices": [{
                            "index": 0,
                            "message": {
                                "role": "assistant",
                                "content": response_text
                            },
                            "finish_reason": finish_reason
                        }],
                        "usage": usage_data
                    }
                    
                    # åœ¨éæµå¼å“åº”ä¸­æ·»åŠ  reasoning_content
                    if reasoning_text:
                        openai_response["choices"][0]["message"]["reasoning_content"] = reasoning_text
                    
                    return jsonify(openai_response)
                finally:
                    pass  # ä¸å†è‡ªåŠ¨åˆ é™¤ä¼šè¯

        except requests.exceptions.RequestException as e:
            debug_print(f"èŠå¤©è¡¥å…¨å¤±è´¥: {e}")
            # è¿”å› OpenAI æ ¼å¼çš„é”™è¯¯
            return jsonify({
                "error": {
                    "message": f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}",
                    "type": "server_error",
                    "param": None,
                    "code": None
                }
            }), 500


# --- Flask åº”ç”¨ ---
app = Flask(__name__)
# é…ç½® CORSï¼Œå…è®¸æ‰€æœ‰æ¥æº (ç”Ÿäº§ç¯å¢ƒè¯·æ ¹æ®éœ€è¦è¿›è¡Œé™åˆ¶)
CORS(app) 

# åˆå§‹åŒ–å®¢æˆ·ç«¯
qwen_client = QwenClient(auth_token=QWEN_AUTH_TOKEN)

@app.route('/v1/models', methods=['GET'])
def list_models():
    """åˆ—å‡ºå¯ç”¨æ¨¡å‹ (æ¨¡æ‹Ÿ OpenAI API)"""
    try:
        # ä»å·²è·å–çš„æ¨¡å‹ä¿¡æ¯æ„é€  OpenAI æ ¼å¼åˆ—è¡¨
        openai_models = []
        for model_id, model_info in qwen_client.models_info.items():
            openai_models.append({
                "id": model_info['info']['id'],
                "object": "model",
                "created": model_info['info']['created_at'],
                "owned_by": model_info['owned_by']
            })
        return jsonify({"object": "list", "data": openai_models})
    except Exception as e:
        print(f"åˆ—å‡ºæ¨¡å‹æ—¶å‡ºé”™: {e}")
        return jsonify({
            "error": {
                "message": f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}",
                "type": "server_error",
                "param": None,
                "code": None
            }
        }), 500

@app.route('/v1/chat/completions', methods=['POST'])
def chat_completions():
    """å¤„ç† OpenAI å…¼å®¹çš„èŠå¤©è¡¥å…¨è¯·æ±‚"""
    openai_request = request.get_json()
    if not openai_request:
        return jsonify({
            "error": {
                "message": "è¯·æ±‚ä½“ä¸­ JSON æ— æ•ˆ",
                "type": "invalid_request_error",
                "param": None,
                "code": None
            }
        }), 400

    stream = openai_request.get("stream", False)
    
    try:
        result = qwen_client.chat_completions(openai_request)
        if stream:
            # å¦‚æœæ˜¯æµå¼å“åº”ï¼Œ`result` æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨å‡½æ•°
            return Response(stream_with_context(result), content_type='text/event-stream')
        else:
            # å¦‚æœæ˜¯éæµå¼å“åº”ï¼Œ`result` æ˜¯ä¸€ä¸ª Flask Response å¯¹è±¡ (jsonify)
            return result
    except Exception as e:
        debug_print(f"å¤„ç†èŠå¤©è¡¥å…¨è¯·æ±‚æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {e}")
        return jsonify({
            "error": {
                "message": f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}",
                "type": "server_error",
                "param": None,
                "code": None
            }
        }), 500

@app.route('/v1/chats/<chat_id>', methods=['DELETE'])
def delete_chat(chat_id):
    """åˆ é™¤æŒ‡å®šçš„å¯¹è¯"""
    try:
        success = qwen_client.delete_chat(chat_id)
        if success:
            return jsonify({"message": f"ä¼šè¯ {chat_id} å·²åˆ é™¤", "success": True})
        else:
            return jsonify({"message": f"åˆ é™¤ä¼šè¯ {chat_id} å¤±è´¥", "success": False}), 400
    except Exception as e:
        debug_print(f"åˆ é™¤ä¼šè¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return jsonify({
            "error": {
                "message": f"åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}",
                "type": "server_error",
                "param": None,
                "code": None
            }
        }), 500

@app.route('/', methods=['GET'])
def index():
    """æ ¹è·¯å¾„ï¼Œè¿”å› API ä¿¡æ¯"""
    return jsonify({
        "message": "åƒé—® (Qwen) OpenAI API ä»£ç†æ­£åœ¨è¿è¡Œã€‚",
        "docs": "https://platform.openai.com/docs/api-reference/chat"
    })

# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return jsonify({"status": "healthy"}), 200

if __name__ == '__main__':
    print(f"æ­£åœ¨å¯åŠ¨æœåŠ¡å™¨äºç«¯å£ {PORT}...")
    print(f"Debugæ¨¡å¼: {'å¼€å¯' if DEBUG_STATUS else 'å…³é—­'}")
    app.run(host='0.0.0.0', port=PORT, debug=False)
